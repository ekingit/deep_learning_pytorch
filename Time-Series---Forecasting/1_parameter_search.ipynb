{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOKk0SKJQTNgd6jNog9yRz9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekingit/DeepForecast/blob/main/1_1_Parameter_opt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zWSAy225VGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d9a8651-6dd5-44de-9d83-a71db987ef10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!cp /content/gdrive/MyDrive/Colab\\ Notebooks/weather_forecast/Data/data.py /content/data.py\n",
        "!cp /content/gdrive/MyDrive/Colab\\ Notebooks/weather_forecast/models.py /content/models.py\n",
        "!cp /content/gdrive/MyDrive/Colab\\ Notebooks/weather_forecast/train.py /content/train.py\n",
        "\n",
        "from data import Sine_Data, Weather_Data\n",
        "from models import local_LSTM\n",
        "from train import train_lstm, test_lstm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loc = '/content/gdrive/MyDrive/Colab Notebooks/weather_forecast/Data/weather_prediction_dataset.csv'\n",
        "data_column = 'BASEL_temp_max'\n",
        "nat_data = Weather_Data(data_loc, data_column)"
      ],
      "metadata": {
        "id": "BzUB2yb7MSOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create an empty .csv to save the results\n",
        "columns = ['model', 'seq_len', 'hidden_size', 'num_layers', 'run_time', 'device','best_epoch', 'num_epoch',\n",
        "           'test_loss','val_loss','train_loss']\n",
        "df = pd.DataFrame(columns=columns)\n",
        "res_loc = '/content/gdrive/MyDrive/Colab Notebooks/weather_forecast/Results/Hyperparameter_Performance_Analysis.csv'\n",
        "df.to_csv(res_loc, index=True)"
      ],
      "metadata": {
        "id": "X6dazu-RTMlN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main(ind, seq_len, hidden_size, num_layers, lr=1e-4, num_epoch=1500, target_seq_len=7, batch_size=128):\n",
        "  '''batch data, define model, train, test, save best model (minimum validation error),\n",
        "     write the results into the .csv file, save train-val plot'''\n",
        "  save_model_path =f'/content/gdrive/MyDrive/Colab Notebooks/weather_forecast/Results/model{ind}.pth'\n",
        "  model_name = 'local_LSTM'\n",
        "  device = 'cuda'\n",
        "  #data\n",
        "  (in_train, out_train), (in_val,out_val), (in_test,out_test) = nat_data.data_chunks(seq_len, target_seq_len)\n",
        "  ds_train = TensorDataset(in_train, out_train)\n",
        "  dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=False)\n",
        "  ds_val = TensorDataset(in_val, out_val)\n",
        "  dl_val = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
        "  ds_test = TensorDataset(in_test, out_test)\n",
        "  dl_test = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "  #model\n",
        "  model = local_LSTM(1,hidden_size,num_layers)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  mse_loss = nn.MSELoss(reduction='sum')\n",
        "  #RUN!\n",
        "  train_loss_list = []\n",
        "  val_loss_list = []\n",
        "  best_loss = 0.5\n",
        "  a=time.time()\n",
        "  for epoch in range(num_epoch):\n",
        "      train_loss = train_lstm(model, dl_train, optimizer, mse_loss, hidden_size, num_layers, device=device)\n",
        "      val_loss = test_lstm(model, dl_val, mse_loss, hidden_size, num_layers, device=device)\n",
        "      if val_loss < best_loss:\n",
        "          best_loss = val_loss\n",
        "          best_epoch = epoch\n",
        "          best_train = train_loss\n",
        "          test_loss = test_lstm(model, dl_test, mse_loss, hidden_size, num_layers, device=device)\n",
        "          torch.save(model.state_dict(), save_model_path)\n",
        "      train_loss_list.append(train_loss)\n",
        "      val_loss_list.append(val_loss)\n",
        "      if epoch %100 == 0:\n",
        "              print(f\"epoch: {epoch} train loss: {train_loss}, validation loss: {val_loss}\")\n",
        "  b=time.time()\n",
        "  #write results to csv\n",
        "  results = {'model':model_name, 'seq_len':seq_len, 'hidden_size':hidden_size, 'num_layers':num_layers}\n",
        "  results['run_time'] = b-a\n",
        "  results['device'] = 'T4_GPU'\n",
        "  results['best_epoch'] = best_epoch\n",
        "  results['num_epoch'] = num_epoch\n",
        "  results['test_loss'] = test_loss\n",
        "  results['val_loss'] = best_loss\n",
        "  results['train_loss'] = best_train\n",
        "\n",
        "  df1 = pd.DataFrame(results, index=[ind])\n",
        "  df1.to_csv(res_loc, mode='a', header=False)\n",
        "  save_plot_path = f'/content/gdrive/MyDrive/Colab Notebooks/weather_forecast/Results/plt{ind}.png'\n",
        "  train_loss_tens = torch.tensor(train_loss_list)\n",
        "  val_loss_tens = torch.tensor(val_loss_list)\n",
        "  plt.plot(train_loss_tens.numpy(),label='train')\n",
        "  plt.plot(val_loss_tens.numpy(),label='test')\n",
        "  plt.axvline(x=best_epoch, color='r', linestyle='--')\n",
        "  plt.title(f'seq_len={seq_len},hidden_size={hidden_size},num_layers={num_layers}')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.ylabel('MSE')\n",
        "  plt.legend()\n",
        "  plt.savefig(save_plot_path)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "uSATocm4HUgL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this (random grid search) or run by hand after analyzing results in every step\n",
        "ind = 0\n",
        "seq_len_list = [14, 30, 50]\n",
        "hidden_size = [10, 20, 50, 100, 200, 300]\n",
        "num_layers = [1, 2, 3]\n",
        "for seq_len in seq_len_list:\n",
        "  for hidden in hidden_size:\n",
        "    for num in num_layers:\n",
        "      main(ind, seq_len, hidden, num)\n",
        "      ind += 1"
      ],
      "metadata": {
        "id": "w-zmOjYI-6Cb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sanity check: compare results with moving avarage.\n",
        "def moving_avarage(data_in, target_seq_len):\n",
        "    Z = data_in.clone()\n",
        "    result = torch.zeros(data_in.shape[0],target_seq_len,1)\n",
        "    result[:,0] = Z.mean(1)\n",
        "    for j in range(1,target_seq_len):\n",
        "        Z = torch.cat([Z[:,1:],Z.mean(1).unsqueeze(-1)],1)\n",
        "        result[:,j] = Z.mean(1)\n",
        "    return result"
      ],
      "metadata": {
        "id": "uPe3OG8oYorP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Sanity check - Moving avarage\n",
        "ind = -1\n",
        "seq_len = 14\n",
        "target_seq_len = 7\n",
        "#data\n",
        "(in_train, out_train), (in_val,out_val), (in_test,out_test) = nat_data.data_chunks(seq_len, target_seq_len)\n",
        "#model run\n",
        "loss = nn.MSELoss()\n",
        "a = time.time()\n",
        "\n",
        "train_moving_avg_preds = moving_avarage(in_train, target_seq_len)\n",
        "train_moving_avg_loss = loss(train_moving_avg_preds, out_train)\n",
        "\n",
        "val_moving_avg_preds = moving_avarage(in_val, target_seq_len)\n",
        "val_moving_avg_loss = loss(val_moving_avg_preds, out_val)\n",
        "\n",
        "test_moving_avg_preds = moving_avarage(in_test, target_seq_len)\n",
        "test_moving_avg_loss = loss(test_moving_avg_preds, out_test)\n",
        "\n",
        "b = time.time()\n",
        "#results\n",
        "results = {'model':'moving_avarage', 'seq_len':14, 'hidden_size':0, 'num_layers':0}\n",
        "results['run_time'] = b-a\n",
        "results['device'] = 'T4_GPU'\n",
        "results['best_epoch'] = 0\n",
        "results['num_epoch'] = 0\n",
        "results['test_loss'] = test_moving_avg_loss.item()\n",
        "results['val_loss'] = val_moving_avg_loss.item()\n",
        "results['train_loss'] = train_moving_avg_loss.item()\n",
        "#save results\n",
        "res_loc = '/content/gdrive/MyDrive/Colab Notebooks/weather_forecast/Results/Hyperparameter_Performance_Analysis.csv'\n",
        "df1 = pd.DataFrame(results, index=[ind])\n",
        "df1.to_csv(res_loc, mode='a', header=False)"
      ],
      "metadata": {
        "id": "qpph_hP8lY7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "anKWNvZe-JNp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
